{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Панасюк Настя, бкл182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0. О данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила собрать корпус отзывов на \"Портрет Дориана Грея\" с livelib. Негативными отзывами я посчитала отзывы с оценкой 0-2 (на livelib в рецензиях обязательно поставить отметку). Обычно такие оценки ставить не принято, поэтому 0-2 значит, что оценка маркированно негативная. Как положительные я хотела брать 4-5, но с 4-ками падала точность, поэтому как положительные я брала 4.5 и 5 (9-10 по десятибальной). <br>\n",
    "Все-таки с тройками-четверками не до конца понятно, какой шкалы придерживается автор в оценивании, что для него значит 3 или 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Пишем краулер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.0 Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()  # чтобы увеличить скорость работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)  # чтобы не заблокировали на сайте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.1. Собираем ссылки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_links(page_number):\n",
    "    for i in range(page_number):\n",
    "        url = f'https://www.livelib.ru/book/1000003526/reviews-portret-doriana-greya-oskar-uajld/~{i+1}#reviews'\n",
    "        response = session.get(url, headers={'User-Agent': ua.random})\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        reviews_bs = soup.find_all('span', {'itemprop':'url'})\n",
    "        rev_links = [link.get_text() for link in reviews_bs]\n",
    "        for link in rev_links:\n",
    "            links.append(link)\n",
    "        time.sleep(random.uniform(2.1, 4.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = collect_links(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1315"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываю ссылки в документ, чтобы не перекачивать заново!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('links.txt', 'w', encoding='utf-8') as f:\n",
    "    for link in links:\n",
    "        f.write(link + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На случай, если надо перечитать список ссылок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('links.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    links = [line for line in text.splitlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2 Переходим по ссылкам и выкачиваем отзывы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила собрать целый датасет, потому что данные уже скачаны. В будущем, по датасету можно сделать какие-то статистические наблюдения в том числе.<br>\n",
    "В датасете (.json): <br>\n",
    "<li>id (номер отзыва на сайте, https://www.livelib.ru/review/1588543 - id = 1588543)</li> \n",
    "<li>user (имя пользователя, вдруг, поведение пользователей с никами на латинице отличается от поведения с никами на кириллице)</li>\n",
    "<li>mark (оценка от 0 до 5)</li>\n",
    "<li>heading (заголовок отзыва. Тоже может быть полезным, например, какие заголовки у положительных отзывов, а какие у отрицательных)</li>\n",
    "<li>review (текст отзыва)</li>\n",
    "<li>likes (количество лайков)</li>\n",
    "<li>comments (количество комментариев)</li>\n",
    "Тоже интересно изучить наполнение отзывов (какие они?) с разным кол-вом лайков/комментариев, что оно говорит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понимаю, что датасет проблемный, потому что роман спорный сам по себе))) И там слишком много этики и \"хороший\" и \"плохой\" употребляется не однозначно в хороших или плохих ревью. Но этим интересно попробовать разобраться именно с ним"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Разбираем страницу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возвращаем словарь с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawldata(rev_id, soup):\n",
    "    user = soup.find('a', {'class':'header-card-user__name'}).text\n",
    "    title = soup.find('h3', {'class':'lenta-card__title'}).text\n",
    "    mark_and_heading = re.findall('(\\S+)', title)\n",
    "    mark = mark_and_heading[0]\n",
    "    if len(mark_and_heading)>1:\n",
    "        heading = ' '.join(mark_and_heading[1:])\n",
    "    else:\n",
    "        heading = '-'  # если отзыв без заголовка\n",
    "    review = soup.find('div', {'id':'lenta-card__text-review-full'})\n",
    "    try:  ## удаляю карточку \"с благодарностью\" - кто советовал прочитать книгу и советовал ли\n",
    "        soup.find('div', {'class':'lenta-card__thanks'}).decompose()  # для исследования это не нужная информация\n",
    "    except:\n",
    "        pass\n",
    "    rev_text = review.text.strip(' \\n')\n",
    "    likes = soup.find('span', {'id':f'vote-plus-span-review-{rev_id}'}).text\n",
    "    comms = soup.find('a', {'class':'sab__link icon-comment'}).text.replace('\\n', '')\n",
    "    return {'id':rev_id, 'user':user, 'mark':mark, 'heading':heading, 'review':rev_text, 'likes':likes, 'comments':comms}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Функция для скачивания странички из списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processlink(link, batch):\n",
    "    url = f'https://{link}'\n",
    "    response = session.get(url, headers={'User-Agent': ua.random})\n",
    "    response.encoding = 'utf-8'\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    rev_id = link.rsplit('/',1)[1]\n",
    "    data = crawldata(rev_id, soup)\n",
    "    batch.append(data)\n",
    "    time.sleep(random.uniform(2.1, 3.2))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Запуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На пробу скачиваю первые 500 - все ли работает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstbatch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f767b73b2db4c639b75b2e4c3209b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for link in tqdm(links[:500]):\n",
    "    try:\n",
    "        review = processlink(link, firstbatch)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.3 Подушка безопасности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first500.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(firstbatch , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first500.json', 'r', encoding='utf-8') as f:\n",
    "    firstbatch = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 оказалось недостаточно, было всего 33 отрицательных, докачиваю остальные отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondbatch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5c2ec5037c412e9d88fff0418493a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=815), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for link in tqdm(links[500:]):\n",
    "    try:\n",
    "        review = processlink(link, secondbatch)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('500further.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(secondbatch , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('500further.json', 'r', encoding='utf-8') as f:\n",
    "    secondbatch = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Обрабатываем отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склеиваю выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = firstbatch + secondbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = []\n",
    "bad = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in reviews:  # разделяю отзывы по оценке 0-2 и 4.5-5\n",
    "    if float(item['mark'])<3:\n",
    "        bad.append(item['review'])\n",
    "    elif float(item['mark'])>4:\n",
    "        good.append(item['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак! Однозначно плохих отзывов только 104, тогда как хороших - 650. Давайте тогда возьмем 80 положительных и все не-тестовые отрицательные (отрицательные отзывы сильно короче, поэтому появляются проблемы с неравным количеством слов).<br>К ним 20 на классификацию. Пусть 11 плохих и 9 хороших."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsample = good[:80]\n",
    "badsample = bad[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsample = []\n",
    "for item in good[110:119]:\n",
    "    testsample.append({'text':item, 'gold':'good'})\n",
    "for item in bad[:11]:\n",
    "    testsample.append({'text':item, 'gold':'bad'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.1 Токенизация через nltk и лемматизация pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(sample):\n",
    "    sampletext=' '.join(sample)\n",
    "    tokens = [w.lower() for w in word_tokenize(sampletext) if w.isalpha()]\n",
    "    lemmatized = [morph.parse(token)[0].normal_form for token in tokens]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем списки слов для положительных и отрицательных отзывов; делаем сет(множество), потом понадобится для словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromgood = preproc(goodsample)\n",
    "goodset = set(fromgood)\n",
    "frombad = preproc(badsample)\n",
    "badset = set(frombad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем словари, в итоге имеем отсортированный Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dict = defaultdict(int)\n",
    "bad_dict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldict(dictionary, lemmatized):\n",
    "    for word in lemmatized:\n",
    "        dictionary[word] +=1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_counted = Counter(filldict(good_dict, fromgood)).most_common()\n",
    "bad_counted = Counter(filldict(bad_dict, frombad)).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.2 Получаем списки слов, характерных только для \"плохих\" и \"хороших\" отзывов; выкидываем единичные употребления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Вопрос</i>: Как выделить уникальные для множества слова, которые не встречаются в другом, умнее, чем setA - setB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosengood = list(goodset-badset)\n",
    "chosenbad = list(badset-goodset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leavespecified(counteddict, comparisonset):\n",
    "    workset = []\n",
    "    for item in counteddict:\n",
    "        if item[0] in comparisonset and item[1]>1:  # убираю \"шум\" - слова, которые встретились меньше одного раза\n",
    "            workset.append(item[0])\n",
    "    return workset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "specifiedgood = leavespecified(good_counted, chosengood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(specifiedgood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы очень большие, так что их убираю. Слова скорее не \"положительные\", а более чем случайные. Но есть положительные оценки типа \"мастерски\", \"необыкновенно\", \"восхитить\", \"изящество\", \"гармонировать\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "specifiedbad = leavespecified(bad_counted, chosenbad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь уже более оформленные отрицательные оценки - \"чёртов\", \"пошлый\", \"пустышка\", \"идиот\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(specifiedbad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.3 Функция, которые определяет положительность и отрицательность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решила оставить препроцессинг каждого отзыва внутри функции, чтобы в функцию можно было подать любой необработанный текст (а не уже лемматизированные списки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictsentiment(review, goodlist, badlist):\n",
    "    lemmatized = preproc(review)\n",
    "    good, bad = 0, 0\n",
    "    for word in lemmatized:\n",
    "        if word in goodlist:\n",
    "            good +=1\n",
    "        elif word in badlist:\n",
    "            bad +=1\n",
    "    if good>bad:\n",
    "        return 'good'\n",
    "    elif bad>good:\n",
    "        return 'bad'\n",
    "    else:\n",
    "        return '-'  # если одинаковое количество, прочерк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказание: good\n",
      "На самом деле: good\n"
     ]
    }
   ],
   "source": [
    "testfirst = predictsentiment(testsample[0]['text'], specifiedgood, specifiedbad)\n",
    "print('Предсказание:', testfirst)\n",
    "print('На самом деле:', testsample[0]['gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Необыкновенная книга, со своей, конечно, моралью.\n",
      "Мне очень понравилось как автор описал личностные качества и портрет главного героя, и в целом мне нравится как пишет автор\n",
      "Сюжет мистически необыкновенен и концовка нестандартнаяя\n"
     ]
    }
   ],
   "source": [
    "print(testsample[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказание: bad\n",
      "На самом деле: good\n"
     ]
    }
   ],
   "source": [
    "testfirst = predictsentiment(testsample[7]['text'], specifiedgood, specifiedbad)\n",
    "print('Предсказание:', testfirst)\n",
    "print('На самом деле:', testsample[7]['gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dolce Vita, или Уродство души\n",
      "\"Манифест европейского эстетизма и шедевр английской художественной прозы\" (по мнению Хорхе Луиса Борхеса) стал вкусной вишней на моём книжном апрельском торте.\n",
      "Роскошный язык, нетривиальный сюжет, нужная толика мистицизма и гедонизма, порция мужского цинизма и страшная трагедия одной человеческой души на фоне общей деградации. Всё, как я люблю!\n",
      "Дориан, по моему мнению, глубоко несчастен не потому, что в нем так много порока, а потому, что никто ему об этом так и не сказал. Была, конечно, попытка у Бэзила. Но самые страшные для нашей совести вещи нам должны говорить те, кто представляется авторитетом. Иначе любая попытка открыть глаза на нашу безнравственность обречена утонуть в волнах негодования. Гарри - единственный, кто мог бы. Но именно ему принадлежит сомнительная заслуга воспитания Дориана в традициях нарциссизма и вакханалий. Да и с Бэзила нельзя снимать долю вины в нравственном падении Грея.\n",
      "Иными словами, Дориан Грей - плод селекции всех и вся, потому он и так злодейски прекрасен, и так обворожительно ужасен.\n"
     ]
    }
   ],
   "source": [
    "print(testsample[7]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказание: good\n",
      "На самом деле: bad\n"
     ]
    }
   ],
   "source": [
    "testfirst = predictsentiment(testsample[9]['text'], specifiedgood, specifiedbad)\n",
    "print('Предсказание:', testfirst)\n",
    "print('На самом деле:', testsample[9]['gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Книга, которая оставила меня равнодушной и не произвела впечатления..История Дориана Грея знакома каждому. Многие читали данный роман, а многие смотрели экранизацию. Сюжет в данном случае можно описать очень кратко и незамысловато: в один прекрасный день талантливый художник Бэззил Холлуорд пишет портрет Дориана Грея. Бэззил вкладывает в него все свои эмоции, свой талант и всю душу. И в итоге.. мы \"видим\" лучшую работу мастера за все его годы! Главный герой, взглянув на портрет, осознаёт насколько он красив и прекрасен. Он восхищён, но в то же время и сильно разочарован. Дориан понимает, что портрет навсегда останется таким прекрасным, а его телесная, физическая оболочка будет без конца увядать с каждым днём.. И в сердцах он проговаривает, что хотел бы навсегда остаться молодым.. А все невзгоды, возрастные изменения перенести на портрет.. Так называемая \"сделка с дьяволом\".. Интересно, не правда ли? Да и кто бы отказался оттого, чтобы навсегда быть молодым и красивым? С романом у меня сложились очень сложные отношения. Начало мне показалось очень затянутым, сюжет немного вялым и всё время хотелось отложить книгу на \"потом\". Были моменты, когда она откровенно раздражала и хотелось её отбросить.. А длинные абзацы размышлений и описаний на протяжении всего чтения становились немного утомительными.. Меня хватало страниц на 20-30 и ничего я с этим сделать не могла.. Книга совершенно не моя.. Не мои герои, не мой сюжет и видимо не мой автор.. НО! так как не в моих правилах оставлять книги на полпути, я её все-таки дочитала.. Конечно же, роман бессмертен, но среди классики встречаются и более увлекательные истории. Впечатления от романа будут у каждого разные и даже многим он действительно понравится, и станет любимой книгой в книжном шкафу!))\n"
     ]
    }
   ],
   "source": [
    "print(testsample[9]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.4 Считаем accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_sentiment_predict(testsample, goodlist, badlist):\n",
    "    results = []\n",
    "    gold = []\n",
    "    for item in testsample:\n",
    "        prediction = predictsentiment(item['text'], goodlist, badlist)\n",
    "        results.append(prediction)\n",
    "        gold.append(item['gold'])\n",
    "    print(results)\n",
    "    print(\"RESULTS:\")\n",
    "    print(\"%d reviews\" % len(testsample))\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'good', '-', 'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad', 'good']\n",
      "RESULTS:\n",
      "20 reviews\n",
      "Accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "testwithk = test_simple_sentiment_predict(testsample, specifiedgood, specifiedbad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распечатала еще вывод, чтобы было видно, где классификатор ошибся. Первые девять на самом деле хорошие, остальные - плохие. Как видно из примера с текстом 9. В отзывах слишком перемешано \"прекрасное\" и \"отвратительное\" - но такой сам роман."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Улучшения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Коэффициент, который будет \"скрадывать\" разницу в количестве положительных и отрицательных отзывов.<br>Я пробовала k = len(specifiedgood) / len(specifiedbad)</li> <br>\n",
    "<li>С такой противорчевой и самой по себе \"аморальной\" книгой должны быть более совершенные методы оценивания положительности/отрицательности, чем проверка по словам. Компьютер должен понимать смысл и сферы действия.</li><br>\n",
    "\n",
    "<b>Как доп. идеи:</b><br>\n",
    "<li>Зависимость оценки от заголовка</li>\n",
    "<li>Соотношение лайков, комментариев и оценки</li><br>\n",
    "<li>\"Выкачать\" корпус отзывов на классику, на livelib \"Портрет\" 12-ый в топе классики. Посмотреть на отзывы повнимательнее.</li>\n",
    "<li>Сделать \"нормирование\" оценок по каждому пользователю. Понять, какая у него шкала оценивания, у кого 4 значит \"мне не совсем понравилось, но неплохо\", а у кого 3 и 4 - \"хорошо, но не дотянуло до шедевра\" (а 5-ки они вообще в иключительных случаях ставят).</li>\n",
    "<li>После \"нормирования\" шкал можно получить взвешенную оценку книги.</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
